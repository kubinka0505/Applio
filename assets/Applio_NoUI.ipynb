{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pKllbPyK_BC"
      },
      "source": [
        "## **Applio NoUI**\n",
        "A simple, high-quality voice conversion tool focused on ease of use and performance.\n",
        "\n",
        "[Support](https://discord.gg/urxFjYmYYh) — [GitHub](https://github.com/IAHispano/Applio) — [Terms of Use](https://github.com/IAHispano/Applio/blob/main/TERMS_OF_USE.md)\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "#### **Acknowledgments**\n",
        "\n",
        "To all external collaborators for their special help in the following areas: Hina (Encryption method), Poopmaster (Extra section), Shirou (UV installer),  Kit Lemonfoot (NoUI inspiration)\n",
        "\n",
        "#### **Disclaimer**\n",
        "By using Applio, you agree to comply with ethical and legal standards, respect intellectual property and privacy rights, avoid harmful or prohibited uses, and accept full responsibility for any outcomes, while Applio disclaims liability and reserves the right to amend these terms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymMCTSD6m8qV"
      },
      "source": [
        "# <font class=\"markdown-google-sans\">**Install Applio**</font>\n",
        "> If the runtime restarts, re-run the installation steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFhAeKGOp9aa",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ## <font class=\"markdown-google-sans\">Mount Google Drive</font>\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CAXW55BQm0PP"
      },
      "outputs": [],
      "source": [
        "#@title ## <font class=\"markdown-google-sans\">Setup runtime environment</font> `(01m 52s)`\n",
        "import os\n",
        "from multiprocessing import cpu_count\n",
        "\n",
        "CPU_Cores = cpu_count()\n",
        "post_process = False\n",
        "hop_length = 128 # Common default value for hop_length, added for consistency across cells\n",
        "\n",
        "!git config --global advice.detachedHead false\n",
        "!git clone https://github.com/kubinka0505/Applio\n",
        "os.chdir(\"/content/Applio\")\n",
        "\n",
        "print()\n",
        "\n",
        "!sudo update-alternatives --set python3 /usr/bin/python3.10\n",
        "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "\n",
        "print()\n",
        "\n",
        "!sudo apt-get install aria2\n",
        "\n",
        "print(\"Installing requirements...\")\n",
        "!uv pip install -q -r requirements.txt\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Finished installing requirements!\")\n",
        "!python core.py \"prerequisites\" --models \"True\" --pretraineds_hifigan \"True\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzaeMYsUE97Y"
      },
      "source": [
        "### **Infer**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "v0EgikgjFCjE"
      },
      "outputs": [],
      "source": [
        "# @title Download model\n",
        "# @markdown Hugging Face or Google Drive\n",
        "model_link = \"https://huggingface.co/Darwin/Darwin/resolve/main/Darwin.zip\"  # @param {type:\"string\"}\n",
        "\n",
        "%cd /content/Applio\n",
        "!python core.py download --model_link \"{model_link}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lrCKEOzvDPRu"
      },
      "outputs": [],
      "source": [
        "# @title Run Inference\n",
        "# @markdown Please upload the audio file to your Google Drive path `/content/drive/MyDrive` and specify its name here. For the model name, use the zip file name without the extension. Alternatively, you can check the path `/content/Applio/logs` for the model name (name of the folder).\n",
        "%cd /content/Applio\n",
        "from pathlib import Path\n",
        "\n",
        "model_name = \"Darwin\"  # @param {type:\"string\"}\n",
        "model_path = Path(f\"/content/Applio/logs/{model_name}\")\n",
        "if not (model_path.exists() and model_path.is_dir()):\n",
        "    raise FileNotFoundError(f\"Model directory not found: {model_path.resolve()}\")\n",
        "\n",
        "# Select either the last checkpoint or the final weight\n",
        "!ls -t \"{model_path}\"/\"{model_name}\"_*e_*s.pth \"{model_path}\"/\"{model_name}\".pth 2> /dev/null | head -n 1 > /tmp/pth.txt\n",
        "pth_file = open(\"/tmp/pth.txt\", \"r\").read().strip()\n",
        "if pth_file == \"\":\n",
        "    raise FileNotFoundError(f\"No model weight found in directory: {model_path.resolve()}\n",
        "Make sure that the file is properly named (e.g. \"{model_name}.pth)\"\")\n",
        "\n",
        "!ls -t \"{model_path}\"/*.index | head -n 1 > /tmp/index.txt\n",
        "index_file = open(\"/tmp/index.txt\", \"r\").read().strip()\n",
        "\n",
        "input_path = \"/content/example.wav\"  # @param {type:\"string\"}\n",
        "output_path = \"/content/output.wav\"\n",
        "export_format = \"WAV\"  # @param ['WAV', 'MP3', 'FLAC', 'OGG', 'M4A'] {allow-input: false}\n",
        "f0_method = \"rmvpe\"  # @param [\"crepe\", \"crepe-tiny\", \"rmvpe\", \"fcpe\", \"hybrid[rmvpe+fcpe]\"] {allow-input: false}\n",
        "f0_up_key = 0  # @param {type:\"slider\", min:-24, max:24, step:0}\n",
        "rms_mix_rate = 0.8  # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "protect = 0.5  # @param {type:\"slider\", min:0.0, max:0.5, step:0.1}\n",
        "index_rate = 0.7  # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "clean_strength = 0.7  # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "split_audio = False  # @param{type:\"boolean\"}\n",
        "clean_audio = False  # @param{type:\"boolean\"}\n",
        "f0_autotune = False  # @param{type:\"boolean\"}\n",
        "formant_shift = False # @param{type:\"boolean\"}\n",
        "formant_qfrency = 1.0 # @param {type:\"slider\", min:1.0, max:16.0, step:0.1}\n",
        "formant_timbre = 1.0 # @param {type:\"slider\", min:1.0, max:16.0, step:0.1}\n",
        "embedder_model = \"contentvec\" # @param [\"contentvec\", \"chinese-hubert-base\", \"japanese-hubert-base\", \"korean-hubert-base\", \"custom\"] {allow-input: false}\n",
        "embedder_model_custom = \"\" # @param {type:\"string\"}\n",
        "\n",
        "!rm -f \"{output_path}\"\n",
        "if post_process:\n",
        "  !python core.py infer --pitch \"{f0_up_key}\" --volume_envelope \"{rms_mix_rate}\" --index_rate \"{index_rate}\" --hop_length \"{hop_length}\" --protect \"{protect}\" --f0_autotune \"{f0_autotune}\" --f0_method \"{f0_method}\" --input_path \"{input_path}\" --output_path \"{output_path}\" --pth_path \"{pth_file}\" --index_path \"{index_file}\" --split_audio \"{split_audio}\" --clean_audio \"{clean_audio}\" --clean_strength \"{clean_strength}\" --export_format \"{export_format}\" --embedder_model \"{embedder_model}\" --embedder_model_custom \"{embedder_model_custom}\" --formant_shifting \"{formant_shift}\" --formant_qfrency \"{formant_qfrency}\" --formant_timbre \"{formant_timbre}\" --post_process \"{post_process}\" --reverb \"{reverb}\" --pitch_shift \"{pitch_shift}\" --limiter \"{limiter}\" --gain \"{gain}\" --distortion \"{distortion}\" --chorus \"{chorus}\" --bitcrush \"{bitcrush}\" --clipping \"{clipping}\" --compressor \"{compressor}\" --delay \"{delay}\" --reverb_room_size \"{reverb_room_size}\" --reverb_damping \"{reverb_damping}\" --reverb_wet_gain \"{reverb_wet_gain}\" --reverb_dry_gain \"{reverb_dry_gain}\" --reverb_width \"{reverb_width}\" --reverb_freeze_mode \"{reverb_freeze_mode}\" --pitch_shift_semitones \"{pitch_shift_semitones}\" --limiter_threshold \"{limiter_threshold}\" --limiter_release_time \"{limiter_release_time}\" --gain_db \"{gain_db}\" --distortion_gain \"{distortion_gain}\" --chorus_rate \"{chorus_rate}\" --chorus_depth \"{chorus_depth}\" --chorus_center_delay \"{chorus_center_delay}\" --chorus_feedback \"{chorus_feedback}\" --chorus_mix \"{chorus_mix}\" --bitcrush_bit_depth \"{bitcrush_bit_depth}\" --clipping_threshold \"{clipping_threshold}\" --compressor_threshold \"{compressor_threshold}\" --compressor_ratio \"{compressor_ratio}\" --compressor_attack \"{compressor_attack}\" --compressor_release \"{compressor_release}\" --delay_seconds \"{delay_seconds}\" --delay_feedback \"{delay_feedback}\" --delay_mix \"{delay_mix}\"\n",
        "else:\n",
        "  !python core.py infer --pitch \"{f0_up_key}\" --volume_envelope \"{rms_mix_rate}\" --index_rate \"{index_rate}\" --protect \"{protect}\" --f0_autotune \"{f0_autotune}\" --f0_method \"{f0_method}\" --input_path \"{input_path}\" --output_path \"{output_path}\" --pth_path \"{pth_file}\" --index_path \"{index_file}\" --split_audio \"{split_audio}\" --clean_audio \"{clean_audio}\" --clean_strength \"{clean_strength}\" --export_format \"{export_format}\" --embedder_model \"{embedder_model}\" --embedder_model_custom \"{embedder_model_custom}\" --formant_shifting \"{formant_shift}\" --formant_qfrency \"{formant_qfrency}\" --formant_timbre \"{formant_timbre}\" --post_process \"{post_process}\"\n",
        "\n",
        "if Path(output_path).exists():\n",
        "  from IPython.display import Audio, display\n",
        "  output_path = output_path.replace(\".wav\", f\".{export_format.lower()}\")\n",
        "  display(Audio(output_path, autoplay=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "J43qejJ-2Tpp"
      },
      "outputs": [],
      "source": [
        "# @title Enable post-processing effects for inference\n",
        "post_process = False # @param{type:\"boolean\"}\n",
        "reverb = False # @param{type:\"boolean\"}\n",
        "pitch_shift = False # @param{type:\"boolean\"}\n",
        "limiter = False # @param{type:\"boolean\"}\n",
        "gain = False # @param{type:\"boolean\"}\n",
        "distortion = False # @param{type:\"boolean\"}\n",
        "chorus = False # @param{type:\"boolean\"}\n",
        "bitcrush = False # @param{type:\"boolean\"}\n",
        "clipping = False # @param{type:\"boolean\"}\n",
        "compressor = False # @param{type:\"boolean\"}\n",
        "delay = False # @param{type:\"boolean\"}\n",
        "\n",
        "reverb_room_size = 0.5 # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "reverb_damping = 0.5 # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "reverb_wet_gain = 0.0 # @param {type:\"slider\", min:-20.0, max:20.0, step:0.1}\n",
        "reverb_dry_gain = 0.0 # @param {type:\"slider\", min:-20.0, max:20.0, step:0.1}\n",
        "reverb_width = 1.0 # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "reverb_freeze_mode = 0.0 # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "\n",
        "pitch_shift_semitones = 0.0 # @param {type:\"slider\", min:-12.0, max:12.0, step:0.1}\n",
        "\n",
        "limiter_threshold = -1.0 # @param {type:\"slider\", min:-20.0, max:0.0, step:0.1}\n",
        "limiter_release_time = 0.05 # @param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
        "\n",
        "gain_db = 0.0 # @param {type:\"slider\", min:-20.0, max:20.0, step:0.1}\n",
        "\n",
        "distortion_gain = 0.0 # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "\n",
        "chorus_rate = 1.5 # @param {type:\"slider\", min:0.1, max:10.0, step:0.1}\n",
        "chorus_depth = 0.1 # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "chorus_center_delay = 15.0 # @param {type:\"slider\", min:0.0, max:50.0, step:0.1}\n",
        "chorus_feedback = 0.25 # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "chorus_mix = 0.5 # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "\n",
        "bitcrush_bit_depth = 4 # @param {type:\"slider\", min:1, max:16, step:1}\n",
        "\n",
        "clipping_threshold = 0.5 # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "\n",
        "compressor_threshold = -20.0 # @param {type:\"slider\", min:-60.0, max:0.0, step:0.1}\n",
        "compressor_ratio = 4.0 # @param {type:\"slider\", min:1.0, max:20.0, step:0.1}\n",
        "compressor_attack = 0.001 # @param {type:\"slider\", min:0.0, max:0.1, step:0.001}\n",
        "compressor_release = 0.1 # @param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
        "\n",
        "delay_seconds = 0.1 # @param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
        "delay_feedback = 0.5 # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "delay_mix = 0.5 # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QkabnLlF2KB"
      },
      "source": [
        "# <font class=\"markdown-google-sans\">**Train**</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## <font class=\"markdown-google-sans\">Setup model variables</font>\n",
        "model_name = \"kubinka0505\" #@param {type: \"string\"}\n",
        "sample_rate = \"48k\" #@param [\"32k\", \"40k\", \"48k\"] {allow-input: false}\n",
        "sr = int(sample_rate.rstrip(\"k\")) * 1000"
      ],
      "metadata": {
        "id": "64V5TWxp05cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBzqm4JkGGa0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ## <font class=\"markdown-google-sans\">Preprocess Dataset</font>\n",
        "import os\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "dataset_path = \"/content/drive/MyDrive/datasets/kubinka0505_Normal\" #@param {type:\"string\"}\n",
        "\n",
        "cut_preprocess = \"Automatic\" #@param [\"Skip\", \"Simple\", \"Automatic\"]\n",
        "chunk_len = 3 #@param {type: \"slider\", min: 0.5, max: 5.0, step: 0.5}\n",
        "overlap_len = 0.3 #@param {type: \"slider\", min: 0, max: 0.5, step: 0.1}\n",
        "process_effects = False #@param{type: \"boolean\"}\n",
        "noise_reduction = False #@param{type: \"boolean\"}\n",
        "noise_reduction_strength = 0.7 #@param {type: \"slider\", min: 0, max:1, step: 0.1}\n",
        "\n",
        "os.chdir(\"/content/Applio\")\n",
        "\n",
        "!python core.py preprocess \\\n",
        "    --model_name \"{model_name}\" \\\n",
        "    --dataset_path \"{dataset_path}\" \\\n",
        "    --sample_rate \"{sr}\" \\\n",
        "    --cpu_cores \"{CPU_Cores}\" \\\n",
        "    --cut_preprocess \"{cut_preprocess}\" \\\n",
        "    --process_effects \"{process_effects}\" \\\n",
        "    --noise_reduction \"{noise_reduction}\" \\\n",
        "    --noise_reduction_strength \"{noise_reduction_strength}\" \\\n",
        "    --chunk_len \"{chunk_len}\" \\\n",
        "    --overlap_len \"{overlap_len}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zWMiMYfRJTJv"
      },
      "outputs": [],
      "source": [
        "#@title ## <font class=\"markdown-google-sans\">Extract Features</font> `(00m 30s)`\n",
        "import os\n",
        "\n",
        "f0_method = \"rmvpe\" #@param [\"crepe\", \"crepe-tiny\", \"rmvpe\"] {allow-input: false}\n",
        "\n",
        "sr = int(sample_rate.rstrip(\"k\")) * 1000\n",
        "include_mutes = 2 #@param {type: \"slider\", min: 0, max: 10, step: 1}\n",
        "embedder_model = \"contentvec\" #@param [\"contentvec\", \"chinese-hubert-base\", \"japanese-hubert-base\", \"korean-hubert-base\", \"custom\"] {allow-input: false}\n",
        "embedder_model_custom = \"\" #@param {type: \"string\"}\n",
        "\n",
        "os.chdir(\"/content/Applio\")\n",
        "\n",
        "!python core.py extract \\\n",
        "    --model_name \"{model_name}\" \\\n",
        "    --f0_method \"{f0_method}\" \\\n",
        "    --hop_length \"{hop_length}\" \\\n",
        "    --sample_rate \"{sr}\" \\\n",
        "    --cpu_cores \"{CPU_Cores}\" \\\n",
        "    --gpu \"0\" \\\n",
        "    --embedder_model \"{embedder_model}\" \\\n",
        "    --embedder_model_custom \"{embedder_model_custom}\" \\\n",
        "    --include_mutes \"{include_mutes}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bHLs5AT4Q1ck"
      },
      "outputs": [],
      "source": [
        "#@title ## <font class=\"markdown-google-sans\">Generate index file</font> `(00m 16s)`\n",
        "import os\n",
        "\n",
        "index_algorithm = \"Auto\" #@param [\"Auto\", \"Faiss\", \"KMeans\"] {allow-input: false}\n",
        "\n",
        "os.chdir(\"/content/Applio\")\n",
        "\n",
        "!python core.py index \\\n",
        "    --model_name \"{model_name}\" \\\n",
        "    --index_algorithm \"{index_algorithm}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TI6LLdIzKAIa"
      },
      "outputs": [],
      "source": [
        "#@title ## <font class=\"markdown-google-sans\">Train</font>\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# ========================\n",
        "# 🔧 Configuration Section\n",
        "# ========================\n",
        "\n",
        "# AutoBackup Parameters\n",
        "cooldown = 1 #@param {type: \"slider\", min: 0, max: 100, step: 0}\n",
        "auto_backups = False #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown Training Settings\n",
        "total_epoch = 20 #@param {type: \"integer\"}\n",
        "batch_size = 8 #@param {type: \"slider\", min: 1, max: 25, step: 0}\n",
        "gpu = 0\n",
        "sr = int(sample_rate.rstrip(\"k\")) * 1000\n",
        "pretrained = True #@param {type: \"boolean\"}\n",
        "cleanup = False #@param {type: \"boolean\"}\n",
        "cache_data_in_gpu = False #@param {type: \"boolean\"}\n",
        "vocoder = \"HiFi-GAN\" #@param [\"HiFi-GAN\"]\n",
        "checkpointing = False\n",
        "tensorboard = True #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown Save Behavior\n",
        "save_every_epoch = 5 #@param {type: \"slider\", min: 1, max: 100, step: 0}\n",
        "save_only_latest = False #@param {type: \"boolean\"}\n",
        "save_every_weights = True #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown Overtraining Detector\n",
        "overtraining_detector = False #@param {type:\"boolean\"}\n",
        "overtraining_threshold = 50 #@param {type: \"slider\", min: 1, max: 100, step: 0}\n",
        "\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown Pretrained Options\n",
        "custom_pretrained = True #@param{type:\"boolean\"}\n",
        "g_pretrained_path = \"http://hf.co/blaise-tk/TITAN/resolve/main/models/medium/48k/pretrained/G-f048k-TITAN-Medium.pth\" #@param {type:\"string\"}\n",
        "d_pretrained_path = \"http://hf.co/blaise-tk/TITAN/resolve/main/models/medium/48k/pretrained/D-f048k-TITAN-Medium.pth\" #@param {type:\"string\"}\n",
        "\n",
        "# ======================\n",
        "# 📁 Path Configuration\n",
        "# ======================\n",
        "\n",
        "LOGS_FOLDER = \"/content/Applio/logs/\"\n",
        "GOOGLE_DRIVE_PATH = \"/content/drive/MyDrive/RVC_Backup\"\n",
        "\n",
        "# ========================\n",
        "# 🧠 Global State Defaults\n",
        "# ========================\n",
        "\n",
        "if \"autobackups\" not in globals():\n",
        "    autobackups = False\n",
        "if \"pretrained\" not in globals():\n",
        "    pretrained = True\n",
        "if \"custom_pretrained\" not in globals():\n",
        "    custom_pretrained = False\n",
        "if \"g_pretrained_path\" not in globals():\n",
        "    g_pretrained_path = \"Custom Path\"\n",
        "if \"d_pretrained_path\" not in globals():\n",
        "    d_pretrained_path = \"Custom Path\"\n",
        "\n",
        "# ====================\n",
        "# 📦 Import Functions\n",
        "# ====================\n",
        "\n",
        "def import_google_drive_backup():\n",
        "    print(\"Importing Google Drive backup...\")\n",
        "    google_drive_path = Path(GOOGLE_DRIVE_PATH)\n",
        "    logs_folder = Path(LOGS_FOLDER)\n",
        "\n",
        "    for root, dirs, files in os.walk(google_drive_path):\n",
        "        root_path = Path(root)\n",
        "\n",
        "        for filename in files:\n",
        "            filepath = root_path / filename\n",
        "\n",
        "            if filepath.is_file():\n",
        "                rel_path = filepath.relative_to(google_drive_path)\n",
        "                backup_filepath = logs_folder / rel_path\n",
        "                backup_folderpath = backup_filepath.parent\n",
        "\n",
        "                if not backup_folderpath.exists():\n",
        "                    backup_folderpath.mkdir(parents=True)\n",
        "                    print(f\"Created backup folder: {backup_folderpath}\", flush=True)\n",
        "\n",
        "                shutil.copy2(filepath, backup_filepath)\n",
        "                print(f\"Imported file from Google Drive backup: {filename}\")\n",
        "\n",
        "    print(\"Google Drive backup import completed.\")\n",
        "\n",
        "def backup_files(logs_dir: str, drive_pth: str):\n",
        "    print(\"\\nStarting backup loop...\")\n",
        "\n",
        "    logs_folder = Path(logs_folder)\n",
        "    drive_path = Path(drive_path)\n",
        "\n",
        "    last_backup_timestamps_path = logs_folder / \"last_backup_timestamps.txt\"\n",
        "    fully_updated = False\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            updated_files = 0\n",
        "            deleted_files = 0\n",
        "            new_files = 0\n",
        "            last_backup_timestamps = {}\n",
        "\n",
        "            try:\n",
        "                with last_backup_timestamps_path.open(\"r\") as f:\n",
        "                    last_backup_timestamps = dict(line.strip().split(\":\", 1) for line in f)\n",
        "            except FileNotFoundError:\n",
        "                pass\n",
        "\n",
        "            for root, dirs, files in os.walk(logs_folder):\n",
        "                # Convert to Path objects\n",
        "                root_path = Path(root)\n",
        "\n",
        "                # Remove unwanted subdirs from walk\n",
        "                if \"zips\" in dirs:\n",
        "                    dirs.remove(\"zips\")\n",
        "                if \"mute\" in dirs:\n",
        "                    dirs.remove(\"mute\")\n",
        "\n",
        "                for filename in files:\n",
        "                    if filename == \"last_backup_timestamps.txt\":\n",
        "                        continue\n",
        "\n",
        "                    filepath = root_path / filename\n",
        "                    if not filepath.is_file():\n",
        "                        continue\n",
        "\n",
        "                    rel_path = filepath.relative_to(logs_folder)\n",
        "                    backup_filepath = drive_path / rel_path\n",
        "                    backup_folderpath = backup_filepath.parent\n",
        "\n",
        "                    if not backup_folderpath.exists():\n",
        "                        backup_folderpath.mkdir(parents=True)\n",
        "\n",
        "                    last_backup_timestamp = last_backup_timestamps.get(str(filepath))\n",
        "                    current_timestamp = filepath.stat().st_mtime\n",
        "\n",
        "                    if last_backup_timestamp is None or float(last_backup_timestamp) < current_timestamp:\n",
        "                        shutil.copy2(filepath, backup_filepath)\n",
        "                        last_backup_timestamps[str(filepath)] = str(current_timestamp)\n",
        "\n",
        "                        if last_backup_timestamp is None:\n",
        "                            new_files += 1\n",
        "                        else:\n",
        "                            updated_files += 1\n",
        "\n",
        "            # Handle deletions\n",
        "            for filepath_str in list(last_backup_timestamps.keys()):\n",
        "                filepath = Path(filepath_str)\n",
        "\n",
        "                if not filepath.exists():\n",
        "                    rel_path = filepath.relative_to(logs_folder)\n",
        "                    backup_filepath = drive_path / rel_path\n",
        "\n",
        "                    if backup_filepath.exists():\n",
        "                        backup_filepath.unlink()\n",
        "                        deleted_files += 1\n",
        "\n",
        "                    del last_backup_timestamps[filepath_str]\n",
        "\n",
        "            if updated_files > 0 or deleted_files > 0 or new_files > 0:\n",
        "                print(f\"Backup Complete: {new_files} new, {updated_files} updated, {deleted_files} deleted.\")\n",
        "                fully_updated = False\n",
        "            elif not fully_updated:\n",
        "                print(\"Files are up to date.\")\n",
        "                fully_updated = True\n",
        "\n",
        "            with last_backup_timestamps_path.open(\"w\") as f:\n",
        "                for filepath, timestamp in last_backup_timestamps.items():\n",
        "                    f.write(f\"{filepath}:{timestamp}\\n\")\n",
        "\n",
        "            time.sleep(cooldown if fully_updated else 0.1)\n",
        "\n",
        "        except Exception as error:\n",
        "            print(f\"An error occurred during backup: {error}\")\n",
        "\n",
        "\n",
        "def start_train():\n",
        "    if tensorboard:\n",
        "        %load_ext tensorboard\n",
        "        %tensorboard --logdir /content/Applio/logs/\n",
        "\n",
        "    os.chdir(\"/content/Applio\")\n",
        "    !python core.py train \\\n",
        "        --model-name \"{model_name}\" \\\n",
        "        --save-every-epoch \"{save_every_epoch}\" \\\n",
        "        --save-only-latest \"{save_only_latest}\" \\\n",
        "        --save-every-weights \"{save_every_weights}\" \\\n",
        "        --total-epoch \"{total_epoch}\" \\\n",
        "        --sample-rate \"{sr}\" \\\n",
        "        --batch-size \"{batch_size}\" \\\n",
        "        --gpu \"{gpu}\" \\\n",
        "        --pretrained \"{pretrained}\" \\\n",
        "        --custom-pretrained \"{custom_pretrained}\" \\\n",
        "        --g-pretrained-path \"{g_pretrained_path}\" \\\n",
        "        --d-pretrained-path \"{d_pretrained_path}\" \\\n",
        "        --overtraining-detector \"{overtraining_detector}\" \\\n",
        "        --overtraining-threshold \"{overtraining_threshold}\" \\\n",
        "        --cleanup \"{cleanup}\" \\\n",
        "        --cache-data-in-gpu \"{cache_data_in_gpu}\" \\\n",
        "        --vocoder \"{vocoder}\" \\\n",
        "        --checkpointing \"{checkpointing}\"\n",
        "\n",
        "# ============================\n",
        "# 🚀 Start Threads and Loops\n",
        "# ============================\n",
        "\n",
        "if autobackups:\n",
        "    autobackups = False\n",
        "    print(\"Autobackup Disabled\")\n",
        "else:\n",
        "    autobackups = True\n",
        "    print(\"Autobackup Enabled\")\n",
        "\n",
        "server_thread = threading.Thread(target=start_train)\n",
        "server_thread.start()\n",
        "\n",
        "if auto_backups:\n",
        "    backup_files(LOGS_FOLDER, GOOGLE_DRIVE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_eU_SoiHIQg"
      },
      "source": [
        "#@title ## <font class=\"markdown-google-sans\">Export model</font>\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "export_for = \"Inference\" #@param [\"Training\", \"Inference\"] {allow-input: false}\n",
        "\n",
        "logs_folder = Path(f\"/content/Applio/logs/{model_name}/\")\n",
        "if not (logs_folder.exists() and logs_folder.is_dir()):\n",
        "    raise FileNotFoundError(f\"{model_name} model folder not found\")\n",
        "\n",
        "export_zip_path = Path(f\"/content/{model_name}.zip\")\n",
        "\n",
        "#-=-=-=-#\n",
        "\n",
        "if export_for.lower().startswith(\"train\"):\n",
        "    # Zip the entire model folder\n",
        "    with zipfile.ZipFile(export_zip_path, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for file in logs_folder.rglob(\"*\"):\n",
        "            if file.is_file():\n",
        "                zipf.write(file, arcname = file.relative_to(logs_folder.parent))\n",
        "else:\n",
        "    # Inference mode: find latest weight file\n",
        "    model_files = sorted(\n",
        "        (logs_folder.glob(f\"{model_name}_*e_*s.pth\")),\n",
        "        key = lambda f: f.stat().st_mtime,\n",
        "        reverse = True\n",
        "    )\n",
        "    if not model_files:\n",
        "        raise FileNotFoundError(\"Model has no weight file, please finish training first\")\n",
        "\n",
        "    weight_path = model_files[0]\n",
        "    weight_name = weight_path.name\n",
        "    index_file = logs_folder / f\"{model_name}.index\"\n",
        "\n",
        "    with zipfile.ZipFile(export_zip_path, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
        "        zipf.write(weight_path, arcname = f\"{model_name}/{weight_name}\")\n",
        "        if index_file.exists():\n",
        "            zipf.write(index_file, arcname = f\"{model_name}/{index_file.name}\")\n",
        "\n",
        "#-=-=-=-#\n",
        "\n",
        "# Move to Google Drive if mounted\n",
        "backup_path = Path(\"/content/drive/MyDrive/RVC_Backup/\")\n",
        "\n",
        "if Path(\"/content/drive\").is_mount():\n",
        "    backup_path.mkdir(parents = True, exist_ok = True)\n",
        "    shutil.move(str(export_zip_path), str(backup_path / export_zip_path.name))\n",
        "    print(f\"Exported model as {backup_path / export_zip_path.name}\")\n",
        "else:\n",
        "    print(f\"Drive not mounted, exporting model as {export_zip_path}\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaKoymXsyEYN"
      },
      "source": [
        "### **Resume training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "d3KgLAYnyHkP"
      },
      "outputs": [],
      "source": [
        "# @title Load a Backup\n",
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# @markdown Put the exact name you put as your Model Name in Applio.\n",
        "modelname = \"My-Project\"  # @param {type:\"string\"}\n",
        "source_path = \"/content/drive/MyDrive/RVC_Backup/\" + modelname\n",
        "destination_path = \"/content/Applio/logs/\" + modelname\n",
        "backup_timestamps_file = \"last_backup_timestamps.txt\"\n",
        "if not os.path.exists(source_path):\n",
        "    print(\n",
        "        \"The model folder does not exist. Please verify the name is correct or check your Google Drive.\"\n",
        "    )\n",
        "else:\n",
        "    time_ = os.path.join(\"/content/drive/MyDrive/RVC_Backup/\", backup_timestamps_file)\n",
        "    time__ = os.path.join(\"/content/Applio/logs/\", backup_timestamps_file)\n",
        "    if os.path.exists(time_):\n",
        "        shutil.copy(time_, time__)\n",
        "    shutil.copytree(source_path, destination_path)\n",
        "    print(\"Model backup loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sc9DzvRCyJ2d"
      },
      "outputs": [],
      "source": [
        "# @title Set training variables\n",
        "# @markdown ### ➡️ Use the same as you did previously\n",
        "model_name = \"Darwin\"  # @param {type:\"string\"}\n",
        "sample_rate = \"40k\"  # @param [\"32k\", \"40k\", \"48k\"] {allow-input: false}\n",
        "f0_method = \"rmvpe\"  # @param [\"crepe\", \"crepe-tiny\", \"rmvpe\"] {allow-input: false}\n",
        "sr = int(sample_rate.rstrip(\"k\")) * 1000"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ymMCTSD6m8qV"
      ],
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}